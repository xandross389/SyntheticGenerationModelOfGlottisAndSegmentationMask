# Synthetic Generation Model Of Glottis And Segmentation Mask
DCGAN and Pix2Pix models for generate synthetic  glotis and segmentation masks from Vovalfolds dataset

In this project, we focus on the generation of synthetic glottis images via Deep Convolutional Generative Adversarial Newtworks (DCGAN); then the resulting images are segmented by another Generative Adversarial Network (GAN), peculiarly a Pix2Pix model, with the aim to obtain the corresponding synthetic labels. Therefore, we investigate state-of-the-art segmentation methods and GANs algorithms to create syntetics images and labels, then we compare them with a ground truth in vivo dataset of human vocal folds. This Deep Convolutional Generative Adversarial Newtworks (DCGAN) is first trained on the original dataset, then, in order to show the quality and validity of our synthetic  images, we use our own already trained model to segment synthetic images. Our approach was tested on Laryngeal Endoscopic Images for Semantic Segmentation dataset (J. B. L. A. K. T. O. Max-Heinrich Laves, «A Dataset of Laryngeal Endoscopic Images for Semantic Segmentation,» [En línea]. Available: https://github.com/imesluh/vocalfolds)
